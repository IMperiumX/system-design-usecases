# Google Drive - System Design Implementation

A hands-on implementation of Google Drive's core architecture for learning distributed systems concepts.

## What This Teaches

This project demonstrates key system design concepts from Chapter 15 of *System Design Interview*:

- **[[block-level-storage]]** - File chunking and delta sync
- **[[strong-consistency]]** - ACID guarantees for metadata
- **[[data-deduplication]]** - Hash-based block reuse
- **[[long-polling]]** - Real-time notifications without WebSockets
- **[[conflict-resolution]]** - First-write-wins with manual merge
- **[[resumable-uploads]]** - Handle network interruptions gracefully
- **[[multi-region-replication]]** - Data durability and availability

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Clients â”‚â”€â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
              â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   LB   â”‚â”€â”€â”€â”€â”€â–¶â”‚  API Servers â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚                â”‚                 â”‚
              â–¼                â–¼                 â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ Block Server â”‚  â”‚ Metadata  â”‚   â”‚ Notification â”‚
      â”‚  (Chunking)  â”‚  â”‚ Cache/DB  â”‚   â”‚   Service    â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ Cloud Storageâ”‚
      â”‚     (S3)     â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

See [docs/01-architecture.md](docs/01-architecture.md) for detailed diagrams.

## Features Implemented

- âœ… **File Upload** - Simple and resumable uploads (max 10 GB)
- âœ… **File Download** - Block-based file reconstruction
- âœ… **Delta Sync** - Only upload changed blocks on edits
- âœ… **Version History** - Track and retrieve file revisions
- âœ… **Conflict Resolution** - Detect concurrent edits, present merge options
- âœ… **Notifications** - Long polling for real-time file change events
- âœ… **Deduplication** - SHA-256 based block dedup across users
- âœ… **Compression** - gzip/bzip2 compression per block
- âœ… **Encryption** - AES-256 encryption at rest
- âœ… **Metadata Caching** - Redis-compatible cache layer

## Quick Start

### Prerequisites

- Python 3.11+
- Docker & Docker Compose (for PostgreSQL)

### Installation

```bash
# Clone and navigate
cd projects/google-drive

# Start database
make docker-up

# Install dependencies
make install

# Initialize database schema
make db-migrate

# Run demo
make demo
```

### Run API Server

```bash
make run
# API docs: http://localhost:8000/docs
```

## Demo Scenarios

The interactive demo (`make demo`) walks through:

1. **User registration and authentication**
2. **Upload a file** - See chunking, compression, encryption in action
3. **Edit file** - Observe delta sync (only changed blocks uploaded)
4. **Concurrent edits** - Trigger sync conflict, resolve manually
5. **Version history** - List and download previous versions
6. **Share file** - Generate shared link
7. **Notifications** - Watch real-time sync events

## Project Structure

```
.
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ 00-analysis.md      # Requirements, scope, trade-offs
â”‚   â”œâ”€â”€ 01-architecture.md  # System diagrams, component deep-dive
â”‚   â”œâ”€â”€ 02-learnings.md     # Key takeaways, interview prep
â”‚   â””â”€â”€ 03-changelog.md     # Implementation history
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py           # Settings, environment vars
â”‚   â”œâ”€â”€ models.py           # Pydantic data models
â”‚   â”œâ”€â”€ storage/
â”‚   â”‚   â”œâ”€â”€ database.py     # SQLAlchemy setup
â”‚   â”‚   â”œâ”€â”€ schema.py       # DB models (User, File, Block, etc.)
â”‚   â”‚   â””â”€â”€ s3_simulator.py # Local filesystem as S3
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ block_processor.py    # Chunking, compression, encryption
â”‚   â”‚   â”œâ”€â”€ file_service.py       # Upload/download orchestration
â”‚   â”‚   â”œâ”€â”€ notification_service.py  # Long polling implementation
â”‚   â”‚   â”œâ”€â”€ conflict_resolver.py  # Sync conflict detection
â”‚   â”‚   â””â”€â”€ cache_service.py      # Metadata caching
â”‚   â””â”€â”€ api.py              # FastAPI endpoints
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_block_processor.py
â”‚   â”œâ”€â”€ test_delta_sync.py
â”‚   â””â”€â”€ test_conflict_resolution.py
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ demo.py             # Interactive demo
â””â”€â”€ storage/                # Simulated S3 (local filesystem)
    â”œâ”€â”€ blocks/             # Encrypted file blocks
    â””â”€â”€ metadata/           # Storage manifests
```

## Key Concepts Demonstrated

### 1. Block-Level Storage

Files are split into 4MB chunks (Dropbox standard). Each block is:
- Hashed (SHA-256) for deduplication
- Compressed (gzip for text, specialized for media)
- Encrypted (AES-256)
- Stored independently in S3

**Code**: `src/services/block_processor.py`

### 2. Delta Sync

Only modified blocks are uploaded on file edits:

```python
# Compare old version blocks vs new file blocks
old_hashes = {block.index: block.hash for block in old_version.blocks}
new_blocks = chunk_file(new_file)

changed = [b for b in new_blocks if old_hashes.get(b.index) != b.hash]
# Upload only `changed` blocks!
```

**Bandwidth savings**: 90% reduction on typical edits

### 3. Strong Consistency

PostgreSQL ACID guarantees prevent divergent file states:
- Cache invalidation on every write
- Synchronous replication to slaves
- Conflict detection via version timestamps

**Code**: `src/storage/database.py`

### 4. Long Polling

Clients hold HTTP connections open (60s timeout) until file change events:

```python
# Client
while True:
    event = await GET("/api/v1/notifications/poll")
    if event:
        sync_file(event.file_id)
```

**Trade-off**: Simpler than WebSockets, sufficient for infrequent updates

## Interview Prep

This implementation prepares you for:

**Clarifying questions**:
- What's the expected scale (DAU, storage, QPS)?
- What file types (text vs binary affects compression)?
- Consistency requirements (strong vs eventual)?
- Latency SLAs (real-time vs near-real-time)?

**Follow-up deep dives**:
- How would you handle 10x traffic spike?
  â†’ *Load balancer auto-scaling, database read replicas, CDN for downloads*
- What if S3 is unavailable?
  â†’ *Multi-region replication, fallback to secondary region*
- How to detect and resolve sync conflicts?
  â†’ *Compare version timestamps, present both versions to user*
- How to optimize bandwidth?
  â†’ *Delta sync, compression, deduplication*

See [docs/02-learnings.md](docs/02-learnings.md) for full interview guide.

## Simplifications vs Production

| Aspect | This Implementation | Production (Google/Dropbox) |
|--------|---------------------|------------------------------|
| Storage | Local filesystem | Multi-region S3/GCS clusters |
| Database | Single PostgreSQL | Sharded DB across 1000s nodes |
| Cache | In-memory dict | Distributed Redis cluster |
| Load balancer | None | Multi-layer LB hierarchy |
| Notifications | Long poll (1 server) | WebSocket cluster (1M conn/server) |
| Encryption | Single AES key | Per-user key encryption (KMS) |
| Auth | Simple JWT | OAuth 2.0, 2FA, device trust |

## Extensions to Try

- [ ] Implement true Redis caching (replace in-memory)
- [ ] Add file sharing with expiration links
- [ ] Implement storage quotas per user
- [ ] Add CDN simulation for downloads
- [ ] Implement versioning retention policies
- [ ] Add metrics dashboard (Prometheus + Grafana)
- [ ] Implement sharding strategy for metadata DB

## Resources

- **System Design Interview** - Chapter 15: Design Google Drive
- [Dropbox scaling talk](https://youtu.be/PE4gwstWhmc) - Engineering insights
- [rsync algorithm](https://rsync.samba.org/tech_report/) - Delta sync foundation
- [S3 documentation](https://aws.amazon.com/s3/) - Object storage patterns

## Related Implementations

- [[url-shortener]] - Simpler key-value storage pattern
- [[key-value-store]] - Deep dive into storage engines
- [[chat-system]] - Real-time messaging (WebSocket vs long poll)

---

**Learning path**: Start with `make demo`, read `docs/00-analysis.md`, then explore code in this order:
1. `src/models.py` - Data structures
2. `src/services/block_processor.py` - Core chunking logic
3. `src/services/file_service.py` - Upload/download orchestration
4. `src/api.py` - API endpoints

Happy learning! ğŸš€
